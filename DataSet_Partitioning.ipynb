{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5b1f43-953b-465d-9c42-589051bc1c8f",
   "metadata": {},
   "source": [
    "# Importing Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4dd51ca-5e13-4510-afe8-b3901a5a2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "import imghdr\n",
    "\n",
    "import tensorflow  as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70abdd7f-15af-4bec-85f6-a995356a8ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58cfb203-c140-4bf9-82c6-6e604e6f627e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cataract', 'normal']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'imgdata_v2/orginal_dataset/'\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93957d93-4d3b-4c90-b8b6-63545dbe1c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cataract :  1038\n",
      "normal :  1074\n"
     ]
    }
   ],
   "source": [
    "for img_class in os.listdir(data_dir):\n",
    "    print(img_class,': ' , len(os.listdir(os.path.join(data_dir, img_class))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1b72e0e-6d32-408b-bb70-16ffeb565e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jpg', 'png', 'jpeg']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_exts = ['jpg', 'png', 'jpeg']\n",
    "img_exts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a962b760-630c-49b0-8f07-a5968725c6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delted  0  images from directory.\n"
     ]
    }
   ],
   "source": [
    "img_removed=0\n",
    "\n",
    "for img_class in os.listdir(data_dir):\n",
    "    for img in os.listdir(os.path.join(data_dir, img_class)):\n",
    "        img_path = os.path.join(data_dir, img_class, img)\n",
    "        img_ext  = imghdr.what(img_path)\n",
    "        try:\n",
    "            if img_ext not in img_exts:\n",
    "                os.remove(img_path)\n",
    "                # print('Removed {}'.format(img_path))\n",
    "                img_removed+=1\n",
    "        except Exception as e:\n",
    "            print('Issue with {}'.format(img_path))\n",
    "\n",
    "print('Delted ', img_removed, ' images from directory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ead46651-b355-4182-9729-d942a977ae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2112 files [00:02, 759.64 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio(data_dir, \n",
    "                   output='imgdata_v2/split_dataset/',\n",
    "                   seed=26,\n",
    "                   ratio=(.7, .2, .1),\n",
    "                   group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7acfe410-c45c-4021-bdeb-4ab9aa26c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cataract test :  105\n",
      "normal test :  109\n",
      "\n",
      "cataract train :  726\n",
      "normal train :  751\n",
      "\n",
      "cataract val :  207\n",
      "normal val :  214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_path = 'imgdata_v2/split_dataset/'\n",
    "for split in os.listdir(split_path):\n",
    "    for img_class in os.listdir(os.path.join(split_path, split)):\n",
    "        print(img_class, split, ': ', len(os.listdir(os.path.join(split_path, split, img_class))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f32dc831-ab0a-4dfc-8fc0-e0264b96b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'imgdata_v2/split_dataset/train/'\n",
    "test_dir = 'imgdata_v2/split_dataset/test/'\n",
    "val_dir = 'imgdata_v2/split_dataset/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "408df635-8f4b-4704-a863-68be974205b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(brightness_range=(0.1, 1.3),\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=True,\n",
    "                            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1b7d036f-f21f-4f05-85ec-c100eaa47564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mtrain_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rgb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msave_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rgb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msave_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"nearest\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Takes the path to a directory & generates batches of augmented data.\n",
       "\n",
       "        Args:\n",
       "            directory: string, path to the target directory. It should contain\n",
       "              one subdirectory per class. Any PNG, JPG, BMP, PPM or TIF images\n",
       "              inside each of the subdirectories directory tree will be included\n",
       "              in the generator. See [this script](\n",
       "              https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n",
       "              for more details.\n",
       "            target_size: Tuple of integers `(height, width)`, defaults to `(256,\n",
       "              256)`. The dimensions to which all images found will be resized.\n",
       "            color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
       "              Whether the images will be converted to have 1, 3, or 4 channels.\n",
       "            classes: Optional list of class subdirectories (e.g. `['dogs',\n",
       "              'cats']`). Default: None. If not provided, the list of classes\n",
       "              will be automatically inferred from the subdirectory\n",
       "              names/structure under `directory`, where each subdirectory will be\n",
       "              treated as a different class (and the order of the classes, which\n",
       "              will map to the label indices, will be alphanumeric). The\n",
       "              dictionary containing the mapping from class names to class\n",
       "              indices can be obtained via the attribute `class_indices`.\n",
       "            class_mode: One of \"categorical\", \"binary\", \"sparse\",\n",
       "                \"input\", or None. Default: \"categorical\".\n",
       "                Determines the type of label arrays that are returned:\n",
       "                - \"categorical\" will be 2D one-hot encoded labels,\n",
       "                - \"binary\" will be 1D binary labels,\n",
       "                    \"sparse\" will be 1D integer labels,\n",
       "                - \"input\" will be images identical\n",
       "                    to input images (mainly used to work with autoencoders).\n",
       "                - If None, no labels are returned\n",
       "                  (the generator will only yield batches of image data,\n",
       "                  which is useful to use with `model.predict_generator()`).\n",
       "                  Please note that in case of class_mode None,\n",
       "                  the data still needs to reside in a subdirectory\n",
       "                  of `directory` for it to work correctly.\n",
       "            batch_size: Size of the batches of data (default: 32).\n",
       "            shuffle: Whether to shuffle the data (default: True) If set to\n",
       "              False, sorts the data in alphanumeric order.\n",
       "            seed: Optional random seed for shuffling and transformations.\n",
       "            save_to_dir: None or str (default: None). This allows you to\n",
       "              optionally specify a directory to which to save the augmented\n",
       "              pictures being generated (useful for visualizing what you are\n",
       "              doing).\n",
       "            save_prefix: Str. Prefix to use for filenames of saved pictures\n",
       "              (only relevant if `save_to_dir` is set).\n",
       "            save_format: one of \"png\", \"jpeg\", \"bmp\", \"pdf\", \"ppm\", \"gif\",\n",
       "              \"tif\", \"jpg\" (only relevant if `save_to_dir` is set). Default:\n",
       "              \"png\".\n",
       "            follow_links: Whether to follow symlinks inside\n",
       "                class subdirectories (default: False).\n",
       "            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
       "              `validation_split` is set in `ImageDataGenerator`.\n",
       "            interpolation: Interpolation method used to resample the image if\n",
       "              the target size is different from that of the loaded image.\n",
       "              Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n",
       "              If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n",
       "              supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n",
       "              `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n",
       "            keep_aspect_ratio: Boolean, whether to resize images to a target\n",
       "              size without aspect ratio distortion. The image is cropped in\n",
       "              the center with target aspect ratio before resizing.\n",
       "\n",
       "        Returns:\n",
       "            A `DirectoryIterator` yielding tuples of `(x, y)`\n",
       "                where `x` is a numpy array containing a batch\n",
       "                of images with shape `(batch_size, *target_size, channels)`\n",
       "                and `y` is a numpy array of corresponding labels.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mDirectoryIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_aspect_ratio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_to_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msave_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\joshu\\appdata\\roaming\\python\\python310\\site-packages\\keras\\preprocessing\\image.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_datagen.flow_from_directory??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8e62e15d-c2cd-4470-946f-6576f96b990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dir = 'imgdata_v2/split_dataset/train/augmented/'\n",
    "\n",
    "# for img_class in os.listdir(train_dir):\n",
    "#     for img in os.listdir(os.path.join(train_dir, img_class)):\n",
    "        # img_path = os.path.join(train_dir, img_class, img)\n",
    "img_path = 'imgdata_v2/split_dataset/train/cataract/_1_5346540.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_reshaped = img.reshape((1,)+img.shape)\n",
    "\n",
    "i=1\n",
    "for batch in train_datagen.flow(img_reshaped,\n",
    "                         batch_size=1,\n",
    "                         save_to_dir=os.path.join(augmented_dir),\n",
    "                         save_prefix='DA',\n",
    "                         save_format='jpg'):\n",
    "    i+=1\n",
    "    if i>5: break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b7172-8a66-4e91-942c-3dcf519eae41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
