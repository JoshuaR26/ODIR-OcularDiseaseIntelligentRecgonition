{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f8d522-2748-4458-bb16-f399e8f57261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "import imghdr\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6c733b-4cd0-4115-8d29-d2771aa419d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e397c587-8ec2-4e65-abab-78fd81471428",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data_dir = 'DataSet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d1fcb8e-6632-4bad-9fb5-631f85cfca52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jpg', 'jpeg', 'png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_exts = ['jpg', 'jpeg', 'png']\n",
    "img_exts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a24e73-e1ff-49d4-a8db-38a4d4419b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9371a3d-3143-468e-b05c-674ed1dba0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists\n"
     ]
    }
   ],
   "source": [
    "new_data_dir = 'PreProcessed_Dataset'\n",
    "try:\n",
    "    os.mkdir(new_data_dir)\n",
    "    print('Folder created Successfully')\n",
    "except Exception:\n",
    "    print('Folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b9746b-a522-427a-a085-4c744038f9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cataract', 'glaucoma', 'diabetic_retinopathy', 'normal']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['cataract', 'glaucoma', 'diabetic_retinopathy', 'normal',]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58dd51f-d0bf-494e-a385-81df1f638a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder cataract already exists\n",
      "Folder glaucoma already exists\n",
      "Folder diabetic_retinopathy already exists\n",
      "Folder normal already exists\n"
     ]
    }
   ],
   "source": [
    "for img_class in classes:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(new_data_dir, img_class))\n",
    "    except Exception:\n",
    "        print('Folder {} already exists'.format(img_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9924bfe-c900-437f-a347-0184ca01a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([0,0,0])\n",
    "higher = np.array([30,30,30])\n",
    "\n",
    "def crop(img):\n",
    "    img_copy = img.copy()\n",
    "    mask = cv2.inRange(img, lower, higher)\n",
    "    inverted_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    cont,_ = cv2.findContours(inverted_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    img_cont = cv2.drawContours(img, cont, -1, 255, 10)\n",
    "\n",
    "    c = max(cont, key=cv2.contourArea)\n",
    "    x, y, w, h= cv2.boundingRect(c)\n",
    "    img_box = cv2.rectangle(img, (x,y), (x+w, y+h), 255, 10)\n",
    "\n",
    "    img_crop = img_copy[y:y+h, x:x+w]\n",
    "\n",
    "    return img_crop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0f58947-34d6-4cac-9640-3d9bd2865913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_white(img_path):\n",
    "    os.remove(img_path)\n",
    "    print('White backgorunded image removed successfully {}'.format(img_path))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "348bb05c-4d67-4b0f-8916-58f7d89e133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharpen = np.array([[-1,-1,-1],\n",
    "                          [-1,9,-1],\n",
    "                          [-1,-1,-1]])\n",
    "\n",
    "def sharpen(img):\n",
    "    img_sharpen = cv2.filter2D(img, -1, kernel_sharpen)\n",
    "    return img_sharpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a25c3b-0eff-4be6-b0f1-a1c3f76523ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(img, image_class, image):\n",
    "    new_path = os.path.join(new_data_dir, image_class, image)\n",
    "    try:\n",
    "        plt.imsave(new_path, img)\n",
    "    except Exception:\n",
    "        print('File already exists {}'.format(new_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84cf0fa8-795b-4b6a-9413-46f72f7cc25a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(og_data_dir, image_class, image)\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m----> 5\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]) :\n\u001b[0;32m      7\u001b[0m     img_crop \u001b[38;5;241m=\u001b[39m crop(img)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "for image_class in os.listdir(og_data_dir):\n",
    "    for  image in os.listdir(os.path.join(og_data_dir, image_class)):\n",
    "        img_path = os.path.join(og_data_dir, image_class, image)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if (img.shape[0] != img.shape[1]) :\n",
    "            img_crop = crop(img)\n",
    "            img_sharpen = sharpen(img_crop)\n",
    "            # img_resized = cv2.resize(img_sharpen, (512, 512))\n",
    "            save(img_sharpen, image_class, image)\n",
    "        elif (img[0][0][0] == 255):\n",
    "            continue\n",
    "        else :\n",
    "            # img_resized = cv2.resize(img, (512, 512))\n",
    "            save(img, image_class, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19c39c-dac4-47da-8886-5d96c18f1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(new_data_dir, image_size=(512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb64410-bfbc-4aeb-acdf-d50929f96fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = data.as_numpy_iterator().next()\n",
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38922d-f685-4f4c-b5da-c08f39e73883",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 5, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:25]):\n",
    "    row = idx//5\n",
    "    col = idx%5\n",
    "    axs[row, col].imshow(img.astype(int))\n",
    "    axs[row, col].axis('off')\n",
    "    axs[row, col].set_title(classes[batch[1][idx]], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5842b-ef85-47ff-b604-9f7c684de052",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()[0].max(), data.as_numpy_iterator().next()[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe3752-88ec-4d06-858e-bf3addeb7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c9173-79fd-4265-86db-eb3176aa97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()[0].max(), data.as_numpy_iterator().next()[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88cc9f-2731-4d6d-a598-1b41c1c24b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46b60f-99f0-4530-be70-661de09e08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int(len(data)*0.7)\n",
    "val_size = int(len(data)*0.2) + 1\n",
    "test_size = int(len(data)*0.1)\n",
    "\n",
    "training_size + val_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353ec13-4a60-467f-9eaa-5b47bc01503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(training_size)\n",
    "val_data = data.skip(training_size).take(val_size)\n",
    "test_dat = data.skip(training_size + val_size).take(test_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
