{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12df19d0-a1d1-437e-9312-939178042e2f",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c0bd6f-9296-48df-828a-7ecf90497ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a76aff-9f08-4a47-bc39-744af496d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d545e3d-aa46-40b4-bdf2-92179e0d76b0",
   "metadata": {},
   "source": [
    "# Image Enhancement Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec24c6e-eab5-4c1e-8518-5995b1d31421",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'imgdata_v2/orginal_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856d472-6a5f-4043-a282-1fd6eb104f5a",
   "metadata": {},
   "source": [
    "## Sharpen Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b6e125-426b-4ac6-b795-332404de1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharpen = np.array([[-1,-1,-1],\n",
    "                          [-1,9,-1],\n",
    "                          [-1,-1,-1]])\n",
    "def sharpen(img):\n",
    "    img_sharpen = cv2.filter2D(img, -1, kernel_sharpen)\n",
    "    return img_sharpen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d121b5c-d76f-4245-8d73-51d1dc871b5e",
   "metadata": {},
   "source": [
    "## Crop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b58707-a615-4707-947f-0b650bf8663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([0,0,0])\n",
    "higher = np.array([30,30,30])\n",
    "\n",
    "def crop(img):\n",
    "    img_copy = img.copy()\n",
    "    mask = cv2.inRange(img_copy, lower, higher)\n",
    "    inv_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    cont, _ = cv2.findContours(inv_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    cv2.drawContours(img_copy, cont, -1, (0,255,0), 20)\n",
    "\n",
    "    c = max(cont, key = cv2.contourArea)\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    img_cropped = img[y:y+h,x:x+w]\n",
    "    return img_cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01959c6-395b-4a20-9ffe-d6d45f339d7b",
   "metadata": {},
   "source": [
    "# Preprocessing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bef8c1d-4a58-4845-b8ca-54a63f70ac19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgdata_v2/orginal_dataset/cataract\\2174_right.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2175_left.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2176_left.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2177_right.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2178_right.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2179_right.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2180_left.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2180_right.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2181_left.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2181_right.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2182_left.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\2182_right.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_130_3561448.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_130_7837321.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_131_7587386.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_131_863673.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_132_7102134.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_133_1300923.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_135_5639464.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_135_7789155.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_137_7856304.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_138_1949117.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_139_583821.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_140_1534199.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_141_3457945.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_141_9740629.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_142_7918627.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_143_1247400.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/cataract\\_143_9392801.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/normal\\2957_left.jpg White-background image successfully removed\n",
      "imgdata_v2/orginal_dataset/normal\\2957_right.jpg White-background image successfully removed\n"
     ]
    }
   ],
   "source": [
    "for img_class in os.listdir(data_dir):\n",
    "    for img in os.listdir(os.path.join(data_dir, img_class)):\n",
    "        img_path = os.path.join(data_dir, img_class, img)\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if img[0][0][0] == 255:\n",
    "            os.remove(img_path)\n",
    "            print('{} White-background image successfully removed'.format(img_path))\n",
    "        else:\n",
    "            img_crop = crop(img)\n",
    "            img_resize = cv2.resize(img_crop, (512, 512))\n",
    "            img_sharpen = sharpen(img_resize)\n",
    "            plt.imsave(img_path, img_sharpen)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1397980-4476-4bbe-b9bf-2aed36a56538",
   "metadata": {},
   "source": [
    "# Splitting Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82a7e62f-2bc3-458f-8d3c-9ca3081c08a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cataract :  1009\n",
      "normal :  1072\n"
     ]
    }
   ],
   "source": [
    "for img_class in os.listdir(data_dir):\n",
    "    print(img_class,': ', len(os.listdir(os.path.join(data_dir, img_class))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "171973a5-e709-4434-80ae-d2bfa6e3f8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2081 files [00:02, 831.57 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio(data_dir, \n",
    "                   output='imgdata_v2/split_dataset/',\n",
    "                   seed=26,\n",
    "                   ratio=(.7, .2, .1),\n",
    "                   group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5346843-bc7d-4a8b-a640-d0246a2dca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cataract test :  102\n",
      "normal test :  108\n",
      "\n",
      "cataract train :  706\n",
      "normal train :  750\n",
      "\n",
      "cataract val :  201\n",
      "normal val :  214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_path = 'imgdata_v2/split_dataset/'\n",
    "\n",
    "for split in os.listdir(split_path):\n",
    "    for img_class in os.listdir(os.path.join(split_path, split)):\n",
    "        print(img_class, split, ': ', len(os.listdir(os.path.join(split_path, split, img_class))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e9897d1-7bda-419d-a90f-8095bb2c702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ded7932-60ab-4305-a85e-76b518529834",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(split_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0b0c9b-aa1e-4e60-b271-fd02c60ee85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(os.path.join(split_path, 'train_aug'))\n",
    "except Exception as e:\n",
    "    print('Folder already exists.')\n",
    "\n",
    "train_aug_dir = os.path.join(split_path, 'train_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b645c46-0085-4223-8d4e-4425b82f2ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cataract augmented :  3447\n",
      "normal augmented :  3604\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(brightness_range=(0.1, 1.5),\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             fill_mode='constant')\n",
    "\n",
    "for img_class in os.listdir(train_dir):\n",
    "    aug_class_dir = os.path.join(train_aug_dir, img_class)\n",
    "    try:\n",
    "        os.mkdir(aug_class_dir)\n",
    "    except Exception as e:\n",
    "        print(img_class, 'Folder already exists')\n",
    "        \n",
    "    for img in os.listdir(os.path.join(train_dir, img_class)):\n",
    "        img = load_img(os.path.join(train_dir, img_class, img))\n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((1, )+img.shape)\n",
    "        i=0\n",
    "        for batch in train_datagen.flow(img,\n",
    "                                       batch_size=16,\n",
    "                                       save_to_dir=aug_class_dir,\n",
    "                                       save_format='jpg',\n",
    "                                       save_prefix='aug'):\n",
    "            i += 1\n",
    "            if i>5:\n",
    "                break;\n",
    "    print(img_class, 'augmented : ', len(os.listdir(aug_class_dir)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
